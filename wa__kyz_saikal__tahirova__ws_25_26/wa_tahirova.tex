\documentclass[a4paper,12pt]{article}

% --- Sprach- und Kodierungseinstellungen ---
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[ngerman]{babel}

% --- Typografie ---
\usepackage{lmodern}
\usepackage{microtype}
\usepackage{csquotes} % Korrekte deutsche Anführungszeichen
\usepackage{setspace}
\onehalfspacing

% --- Seitenlayout ---
\usepackage[left=2.5cm,right=2.5cm,top=3cm,bottom=3cm]{geometry}
\usepackage{indentfirst}
\setlength{\parindent}{1.25em} % Отступ первой строки
\setlength{\parskip}{0pt}      % Без дополнительного вертикального расстояния

\usepackage{chngcntr}
\counterwithin{table}{section}

% --- Grafiken ---
\usepackage{graphicx}
\graphicspath{{./img/}} 

% --- Farben, Links, URLs ---
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{url}
\urlstyle{same}
\hypersetup{
    pdftitle={Nutzung von Sprachmodellen zur Verbesserung von Bezeichnern in Java-Programmen},
    pdfauthor={Kyz Saikal Tahirova},
    pdfsubject={Wissenschaftliche Arbeit},
    pdfkeywords={Sprachmodelle, Java, Bezeichner, Programmierung},
    colorlinks=true,
    linkcolor=black,
    citecolor=black,
    urlcolor=blue,
    pdfpagemode=UseOutlines
}

\usepackage{enumitem}
\setlist{itemsep=3pt, topsep=3pt, parsep=0pt, partopsep=0pt}

% --- Mathe und Tabellen ---
\usepackage{amsmath,amssymb,booktabs}

% --- Quellcode ---
\usepackage{listings}
\lstdefinestyle{javaStyle}{
    language=Java,
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue!70!black}\bfseries,
    stringstyle=\color{red!60!black},
    commentstyle=\color{gray},
    numbers=left,
    numberstyle=\tiny\color{gray},
    stepnumber=1,
    showstringspaces=false,
    tabsize=4,
    breaklines=true,
    frame=single,
    inputencoding=utf8,
    extendedchars=true,
    literate={ä}{{\"a}}1 {ö}{{\"o}}1 {ü}{{\"u}}1 {ß}{{\ss}}1
}
\lstset{style=javaStyle}

% --- Verzeichnisse ---
\usepackage[nottoc,notlof,notlot]{tocbibind}

% ===============================
%           Dokument
% ===============================
\begin{document}

% --- Titelseite ---
\begin{titlepage}
    \centering
    \includegraphics[width=0.7\textwidth]{WHZ-Logo.jpg}\\[1cm]

    {\Large\textbf{Westsächsische Hochschule Zwickau}}\\[1ex]
    {\large Fakultät für Physikalische Technik und Informatik}\\[4cm]

    {\LARGE\textbf{Wissenschaftliche Arbeit}}\\[1cm]

    {\Large\textbf{Thema:}}\\[0.5cm]
    {\Large Nutzung von Sprachmodellen zur Verbesserung von Bezeichnern in Java-Programmen}\\[3cm]

    \begin{tabular}{rl}
        Vorgelegt von: & Kyz Saikal Tahirova \\
        % Matrikel-Nr.:  & 66110               \\
        Studiengang:   & Informatik          \\
        Betreuer:      & Prof.\ Dr.\ Laue    \\
        Abgabetermin:  & 15.12.2025          \\
    \end{tabular}
\end{titlepage}

\setcounter{page}{2}

\clearpage

% --- Inhaltsverzeichnis ---
\tableofcontents
\clearpage

% --- Hauptteil ---
\section*{Kapitel 1}
\section{Einleitung}

Sprachmodelle werden in der Softwareentwicklung immer häufiger eingesetzt, um
Entwickler bei Analyse- und Review-Aufgaben zu unterstützen. Ein wichtiger
Anwendungsbereich ist die Bewertung von Bezeichnern im Quellcode. Klare und
verständliche Namen vereinfachen die Wartung, während verschwommene Bezeichner
zu Fehlern und erhöhtem Aufwand führen
\cite{identifiernamesinfluencecodequality}.

Diese Arbeit untersucht die Zuverlässigkeit moderner Sprachmodelle bei der
Einschätzung von Java-Bezeichnern. Bewertet werden Verständlichkeit,
semantische Angemessenheit, Einhaltung etablierter Namenskonventionen
\cite{oracle} sowie die Erkennung linguistischer Anti-Muster
\cite{arnaoudova2014}. Unter linguistischen Anti-Mustern versteht man
systematische sprachliche Probleme in Bezeichnern, die Klarheit und Lesbarkeit
beeinträchtigen.

Ziel der Untersuchung ist es zu prüfen, ob Sprachmodelle hilfreiche und
konsistente Hinweise zur Verbesserung von Bezeichnern liefern können. Hierfür
werden mehrere Hinweis-Varianten entwickelt und schrittweise verfeinert. Die
Analyse erfolgt anhand von Java-Beispielen mit sowohl problematischen als auch
korrekten Bezeichnern, um die Erkennung tatsächlicher Verstöße und das
Auftreten unbegründeter Warnungen („False Positives“) zu bewerten. Frühere
Arbeiten zeigen bereits, dass LLM-generierter Code zu semantischen
Fehlbenennungen und strukturellen Qualitätsproblemen neigt
\cite{llmsmells2025,llmmethodnames2025,aitomaticprogramming}.

Die zentrale Forschungsfrage lautet:
\begin{quote}
    Wie zuverlässig können Sprachmodelle Java-Bezeichner hinsichtlich Verständlichkeit, Bedeutung, Konventionen und linguistischer Anti-Muster bewerten?
\end{quote}

Die Arbeit ist in mehrere Kapitel gegliedert:

\begin{enumerate}
    \item \textbf{Kapitel 1 (Einleitung).} Vorstellung des Themas, Zielsetzung, Relevanz von Sprachmodellen in der Softwareentwicklung sowie die Forschungsfrage.
    \item \textbf{Kapitel 2 (Theoretischer Hintergrund).} Überblick über Java-Bezeichner, Namenskonventionen und linguistische Anti-Muster.
    \item \textbf{Kapitel 3 (Methodik und Durchführung).} Aufbau der Untersuchung, Entwicklung der Hinweis-Varianten sowie Beschreibung der verwendeten Java-Beispiele. \textit{Eine automatische Pipeline wird nur theoretisch erwähnt.}
    \item \textbf{Kapitel 4 (Evaluation).} Auswertung der Ergebnisse und systematische Bewertung der Antworten der Sprachmodelle.
    \item \textbf{Kapitel 5 (Diskussion und Schluss).} Grenzen der Methode, Verbesserungsideen, Ausblick auf weitere Forschung.

\end{enumerate}

Hinweis: In dieser ersten Version der Arbeit wird der automatische
Pipeline-Ansatz nur theoretisch erläutert, da die Umsetzung zum jetzigen
Zeitpunkt noch nicht erfolgt ist. In einer späteren Version könnte diese
Funktion ergänzt werden, um den gesamten Prozess der Bezeichnerverbesserung
automatisch abzubilden.

\newpage
\section*{Kapitel 2}
\section{Theoretischer Hintergrund}
Dieser Abschnitt bietet einen Überblick über Java-Bezeichner, etablierte
Namenskonventionen sowie linguistische Anti-Muster, die als Grundlage für die
spätere Analyse dienen. Die Relevanz dieser Konzepte ergibt sich aus
empirischen Studien, die zeigen, dass Bezeichner einen erheblichen Einfluss auf
die Verständlichkeit und Qualität von Quellcode haben
\cite{identifiernamesinfluencecodequality}.

\subsection{Java-Bezeichner}

Java-Bezeichner sind die Namen von Variablen, Methoden, Klassen,
Schnittstellen, Konstanten und Paketen. Sie sollen die Funktion und den Zweck
des Codes verständlich machen. Die Studie von Butler et al.
\cite{identifiernamesinfluencecodequality} zeigt, dass unklare, inkonsistente
oder mehrdeutige Namen mit geringer Wartbarkeit, erhöhter Komplexität und
häufigeren Warnungen in statischen Analysewerkzeugen verbunden sind. Im
Gegensatz dazu können klare Namen ein einfacher Indikator für eine hohe
Qualität des Quellcodes sein.

\subsection{Namenskonventionen in Java}

Die offiziellen Java-Konventionen \cite{oracle} empfehlen konsistente
Schreibweisen und semantisch präzise Nomenphrasen. Dazu gehören:

\begin{itemize}
    \item \textbf{Klassen und Schnittstellen.} Großschreibung jedes Wortanfangs (CamelCase), z.\,B. \texttt{CustomerAccount}, \texttt{ PaymentProcessor}. Allgemein sollten aussagekräftige Nomenphrasen verwendet werden, etwa \texttt{EnrolledStudents} oder \texttt{ NumberOfValidCreditCards}.
    \item \textbf{Methoden.} Verben oder Verbphrasen wie \texttt{ calculateTotal()} oder \texttt{validateInput()}.
    \item \textbf{Attribute/Variablen.} camelCase und präzise Bedeutung, z.\,B. \texttt{userName}, \texttt{itemCount}.
\end{itemize}

Ein Name soll beschreiben, was ein Element speichert oder ausführt. Unklare
Begriffe wie \texttt{tmp}, \texttt{data} oder \texttt{handle} lassen zu viel
Interpretationsspielraum und führen schnell zu Missverständnissen.

\subsection{Linguistische Anti-Muster}

Linguistische Anti-Muster (Linguistic Anti-Patterns) wurden erstmals
systematisch von Arnaoudova et al. beschrieben \cite{arnaoudova2014}. Sie
bezeichnen wiederkehrende sprachliche Probleme in Bezeichnern, Kommentaren oder
Signaturen, bei denen Name und tatsächliches Verhalten nicht übereinstimmen.
Dies führt zu kognitiven Brüchen und erschwert das Programmverständnis. Die linguistischen Anti-Muster lassen sich in zwei Hauptgruppen einteilen.

Methodenbezogene Anti-Muster:

\begin{enumerate}
    \item \textit{Kategorie A - tut mehr als der Name sagt.}
          Die Methode führt zusätzliche Aktionen aus.
          Beispiel: \texttt{getUser()} validiert oder speichert Daten.

    \item \textit{Kategorie B - sagt mehr als sie tut.}
          Der Name verspricht Funktionalität, die nicht implementiert ist.
          Beispiel: \texttt{validate()} besitzt den Rückgabetyp \texttt{void}.

    \item \textit{Kategorie C - tut das Gegenteil.}
          Name und Verhalten widersprechen sich.
          Beispiel: \texttt{disable()} erzeugt einen \texttt{EnableState}.
\end{enumerate}

Attributbezogene Anti-Muster:
\begin{enumerate}
    \setcounter{enumi}{3}
    \item \textit{Kategorie D - enthält mehr als der Name sagt.}
          Beispiel: ein als Prädikat benannter Bezeichner, dessen Typ jedoch kein \texttt{boolean} ist.

    \item \textit{Kategorie E - Name sagt mehr als enthalten ist.}
          Beispiel: \texttt{users} als Name für ein einzelnes Objekt.

    \item \textit{Kategorie F - Name und Inhalt widersprechen sich.}
          Beispiel: Attributname und Typ bilden Antonyme.
\end{enumerate}

\subsection{Große Sprachmodelle (LLMs)}

Sprachmodelle werden zunehmend zur Bewertung von Quellcode verwendet
\cite{aitomaticprogramming}. Studien zeigen jedoch, dass LLMs zwar Muster
erkennen können, aber gleichzeitig zu einer oberflächlichen Analyse neigen, insbesondere wenn nur Identifikatoren geändert oder semantisch irrelevante Änderungen vorgenommen werden \cite{llmmaintainablereliable2025}. Darüber hinaus zeigen mehrere Studien eine hohe Rate an Fehlalarmen („False Positives”) und ungenauen Bewertungen \cite{llmsmells2025, llmdetection2025}.

In dieser Arbeit wird untersucht, wie zuverlässig Sprachmodelle Java-Bezeichner bewerten können und in welchen Fällen weiterhin menschliches Eingreifen erforderlich ist.

\newpage
\section*{Kapitel 3}
\section{Methodik und Durchführung}

\subsection{Auswahl der Sprachmodelle}

Für die Untersuchung wurden zwei verschiedene Modelle über HAWKI\footnote{HAWKI
    dient als Schnittstelle zu OpenAI GPT-4o, Meta LLaMA 3.1 70B Instruct} und ein Modell über Qwen KI abgefragt:

\begin{itemize}
    \item OpenAI GPT-4o,
    \item Meta LLaMA 3.1 70B Instruct,
    \item Alibaba Qwen3-Coder.
\end{itemize}

\subsection{Erstellung der Test-Beispiele}

\subsubsection{Kategorien nach Arnaoudova}

Basierend auf Arnaoudova et al. \cite{arnaoudova2014} wurden zwei Arten von
Beispielen erstellt:

\begin{itemize}
    \item 13 Beispiele mit linguistischen Anti-Mustern (alle Kategorien A–F),
    \item 5 korrekt benannte Beispiele ohne Anti-Muster, um unbegründete Fehlalarme zu erkennen.
\end{itemize}

Jede Kategorie wurde kurz erklärt und durch ein prägnantes Beispiel
illustriert.

\subsubsection{Beispiel-Code}

\textit{Kategorie A1 – „tut mehr als der Name sagt“.} Methode mit \texttt{get} macht mehr als zurückgeben:

\begin{lstlisting}
public class UserManager {
    private User currentUser;

    public User getUser() {
        logAccess(); //Nebenwirkung
        refreshSession(); //weitere Nebenwirkung
        return currentUser;
    }
    
    private void logAccess() {}
    
    private void refreshSession() {}
}
\end{lstlisting}

\textit{Kategorie B3.} Name deutet Rückgabe an, aber \texttt{void}:

\begin{lstlisting}
public class ConfigReader {
    public void getVersion() {
        System.out.println("v1.0");
    }
}
\end{lstlisting}

\textit{Kategorie C1.} Widerspruch zwischen Name und Rückgabewert:

\begin{lstlisting}
public class Config {
   public ControlState disable() {
        return new ControlState(true); // true = enabled
    }

    private static class ControlState {
        public boolean enabled;

        public ControlState(boolean enabled) {
            this.enabled = enabled;
        }
    }
}
\end{lstlisting}

\textit{Kategorie D2.} Prädikatname, Typ nicht Boolean:
\begin{lstlisting}
public class Product {
    public String isAvailable() {
        return "yes";
    }
}
\end{lstlisting}

\textit{Kategorie E1.} Pluralname bei singular Typ:
\begin{lstlisting}
public class CustomerService {
    private Customer customers;
}
\end{lstlisting}

\textit{Kategorie F1.} Name und Typ im Gegensatz:
\begin{lstlisting}
public class FeatureFlag {
    private boolean isEnabled = false;
}
\end{lstlisting}

\subsubsection{Korrekte Beispiele für False-Positive-Tests}

\begin{lstlisting}
public class CustomerService {

      private final CustomerRepository customerRepository;

      public CustomerService(CustomerRepository customerRepository) {
            this.customerRepository = customerRepository;
      }

      public Customer findCustomerById(Long customerId) {
            if (customerId == null || customerId <= 0) {
                  throw new IllegalArgumentException("Customer ID must be positive");
            }
            return customerRepository.findById(customerId);
      }
}

public interface CustomerRepository {
        Customer findById(Long id);
        void save(Customer customer);
        void deleteById(Long id);
    }

\end{lstlisting}

Diese Beispiele enthalten keine Anti-Muster. Ein korrektes Modell darf hier \emph{keine} Warnung ausgeben \cite{llmdetection2025}.

\subsection{Hinweis-Strategien und Iteration}
Die Hinweise wurden iterativ nach Versionen überarbeitet: Version 1 (V1) → Version 2 (V2) → Version 3 (V3) → Version 4 (V4). Das Ziel jeder Iteration war die Qualitätssteigerung der Hinweise (automatischer Überblick) und die Reduzierung der Anzahl von Fehlalarmen. V4 enthält auch eine kurze Definition linguistischer Anti-Muster, damit Modelle diese Kategorien zielorientiert erkennen können.

\paragraph{V1 (Zero-Shot)}
\begin{verbatim}
    Analysieren Sie die Bezeichner im folgenden Java-Code
    und identifizieren Sie mögliche Benennungs- oder Struktur-Anti-Muster.
    [CODE]
\end{verbatim}

\paragraph{V2 (Few-Shot)}
\begin{verbatim}
    Beispiele für gute Bezeichner:
    - Klassen: CustomerAccount, PaymentProcessor
    - Methoden: calculateTotal(), validateInput()
    - Attribute: userName, itemCount
    Analysieren Sie nun folgenden Code:
    [CODE]
\end{verbatim}

\paragraph{V3 (Kontextreicher Hinweis)}
\begin{verbatim}
    Analysieren Sie den Code unter Berücksichtigung von:
    1) Java-Konventionen (Oracle)
    2) Konsistenz zwischen Name, Typ und Verhalten
    3) Verständlichkeit und Bedeutung
    Geben Sie Hinweise für Entwickler.
    [CODE]
\end{verbatim}

\paragraph{V4 (Erklärung der linguistischen Anti-Muster)}
\mbox{}\\
Da unklar ist, ob Modelle linguistische Anti-Muster kennen \cite{arnaoudova2014}, wird in dieser Version eine kurze Erklärung ergänzt.

\begin{verbatim}
    Linguistische Anti-Muster:
    A: Methode tut mehr als Name sagt
    B: Name verspricht mehr als implementiert
    C: Name und Verhalten sind gegensätzlich
    D-F: Inkonsistenzen bei Attributnamen
    Analysieren Sie nun den Code:
    [CODE]
\end{verbatim}

\subsection{Iteratives Vorgehen}

Der Hinweis wurde iterativ verbessert:

\begin{enumerate}
    \item erste Tests mit Version 1,
    \item Analyse der Fehlbewertungen,
    \item Erweiterung um Beispiele (Version 2),
    \item Hinzufügen von Kontextregeln (Version 3),
    \item Ergänzung der Definitionen von Anti-Mustern (Version 4).
\end{enumerate}

Dieses Vorgehen folgt aktuellen Forschungsergebnissen, die die Bedeutung von Hinweis-Gestaltung und Iteration bei der Codeanalyse hervorheben \cite{llmmethodnames2025, aitomaticprogramming}.

\subsection{Durchführung der Tests}

Für jedes der 13 fehlerhaften Beispiele und für die 5 korrekten Beispiele wurde jede Hinweis-Version an alle drei Modelle über HAWKI gesendet. Jede Modellantwort wurde protokolliert und anonymisiert gespeichert.

\subsection{Bewertungskriterien}

Jedes Kriterium wird mit 1-5 Punkten bewertet.

\begin{enumerate}
    \item \textbf{Anti-Muster-Erkennung.} Wurde das Problem erkannt (Ja/Nein)?

    \item \textbf{Korrekturqualität.} Ist der vorgeschlagene neue Name besser? Löst er das Anti-Muster?

    \item \textbf{Konventions-Konformität.} Folgt der neue Code Java-Standards?

    \item \textbf{Semantische Klarheit.} Sind die neuen Namen verständlich?

    \item \textbf{Konsistenz.} Passt alles zusammen?
\end{enumerate}

Zusätzlich wurden Fehlalarme („False Positives“) gesondert untersucht, da aktuelle Forschung zeigt, dass sie bei LLM-basierten Analysen häufig auftreten \cite{llmdetection2025, llmmaintainablereliable2025}.


\newpage
\section*{Kapitel 4}
\section{Evaluation}

Die Untersuchung nutzt insgesamt 18 Java-Beispiele: 13 Beispiele mit linguistischen Anti-Mustern der Kategorien~A--F und 5 korrekte Beispiele ohne Anti-Muster. Jedes Beispiel wurde mit vier Hinweisversionen (V1--V4) an drei Modelle getestet: OpenAI~GPT-4o, Meta~LLaMA~3.1~70B~Instruct und Alibaba~Qwen3-Coder. Damit ergeben sich 216 Modellantworten (18~Beispiele $\times$ 4~Versionen $\times$ 3~Modelle).

\subsection{Ergebnisse nach Modellen}

Tabelle~\ref{tab:modelleigenschaften} zeigt die wichtigsten Unterschiede zwischen den Modellen.% 

\begin{table}[h]
    \centering
    \caption{Vergleich der Modelleigenschaften}

    \label{tab:modelleigenschaften}

    \begin{tabular}{|p{4.3cm}|p{2.8cm}|p{3cm}|p{2.8cm}|}
        \hline
        Aspekt                       & GPT-4o          & LLaMA 3.1 70B             & Qwen3-Coder     \\
        \hline
        Anti-Muster-Nennung (V1--V3) & Selten          & Selten                    & Selten          \\[0.2em]
        \hline
        Anti-Muster-Nennung (V4)     & Häufig, korrekt & Häufig, überinterpretiert & Häufig, korrekt \\[0.2em]
        \hline
        Fehlalarme                   & Keine           & Mehrere (alle Versionen)  & Keine           \\[0.2em]
        \hline
        Durchschnitt (V1--V3)        & 4{,}17          & 4{,}29                    & 3{,}75          \\[0.2em]
        \hline
        Durchschnitt (V4)            & 5{,}00          & 4{,}88                    & 5{,}00          \\
        \hline
    \end{tabular}
\end{table}

\subsubsection{OpenAI GPT-4o}

GPT-4o zeigt in allen Beispielen eine stabile Leistung. In den Hinweisversionen V1 bis V3 beschreibt das Modell die Probleme präzise, verwendet die Anti-Muster-Begriffe jedoch nur selten, etwa wenn es in Beispiel A1 die Nebenwirkungen von \texttt{getUser()} kritisiert, den Fall aber nicht Kategorie A zuordnet (Anti-Muster gefunden = nein, Gesamtpunktzahl 4{,}00).

Mit Hinweisversion~V4 ändert sich dieses Verhalten deutlich: GPT-4o nennt die Kategorien~A--F explizit und erreicht bei allen 13 fehlerhaften Beispielen eine Bewertung von~5{,}00; in Beispiel~A1 wird Anti-Muster~A und in Beispiel~C1 werden die Kategorien~B und~C klar identifiziert.

Bei den korrekten Beispielen bestätigt GPT-4o konsequent die Qualität der Bezeichner, erzeugt keine Fehlalarme und vergibt durchgängig Bewertungen von 5{,}00 Punkten.

\subsubsection{Meta LLaMA 3.1 70B Instruct}

Meta~LLaMA~3.1~70B~Instruct zeigt gemischte Ergebnisse. Bei fehlerhaften Beispielen liefert das Modell in den Versionen~V1 bis~V3 gute Analysen mit Gesamtnoten zwischen 3{,}75 und 4{,}75, nutzt die Anti-Muster-Begriffe jedoch erst ab Version~V4 konsequent. In dieser Version erreicht LLaMA bei mehreren Beispielen (u.\,a.~D1, D2, E1 und E2) jeweils 5{,}00 Punkte und ordnet die Probleme explizit den Kategorien~B,~C oder~D zu.

Problematisch ist das Verhalten bei korrekten Beispielen. Im Beispiel~D1 behauptet LLaMA in allen Versionen, der Code müsse verbessert werden, und schlägt etwa eine Umbenennung von \texttt{isPremium} zu \texttt{hasPremiumMembership} vor, obwohl hier kein Anti-Muster vorliegt (Fehlalarme, Note zwischen 4{,}25 und 4{,}50).

\subsubsection{Alibaba Qwen3-Coder}

Alibaba~Qwen3-Coder verhält sich in vielen Punkten ähnlich wie GPT-4o. In den Versionen~V1 bis~V3 beschreibt das Modell Probleme korrekt, nutzt die Anti-Muster-Kategorien jedoch kaum; die Bewertungen liegen dabei konstant bei etwa 3{,}75. Typische Kommentare lauten, dass ein Name wie \texttt{checkFormat()} ungenau ist oder dass er Unstimmigkeiten beschreibt, die keiner bestimmten Anti-Muster-Kategorie zuzuordnen.

Mit Version~V4 steigt die Leistung von Qwen3-Coder: in allen betrachteten Beispielen (unter anderem B1, B2, B3, F1 und F2) erreicht das Modell eine Bewertung von 5{,}00 und ordnet die Probleme den passenden Kategorien zu; in F1 werden Anti-Muster im Bereich~B und~D--F explizit identifiziert; in F2 Anti-Muster~D.

Bei den korrekten Beispielen verhält sich Qwen3-Coder zuverlässig, erzeugt keine Fehlalarme und bestätigt eine korrekte Bezeichnerpraxis; die Bewertungen liegen auch durchgängig bei 5{,}00 Punkten.

\subsection{Vergleich der Hinweisversionen}

\paragraph{Version 1 (Zero-Shot).}

Ohne Beispiele und ohne Definition der Anti-Muster liefern alle Modelle zwar sinnvolle Kommentare und erkennen semantische Probleme, nennen die Kategorien~A--F jedoch fast nie explizit. Die durchschnittlichen Bewertungen liegen bei etwa 3{,}75 bis 4{,}00 für GPT-4o, 3{,}75 bis 4{,}75 für LLaMA~3.1 und 3{,}00 bis 3{,}75 für Qwen3-Coder; Anti-Muster werden nicht erkannt.

\paragraph{Version 2 (Few-Shot).}

Die Beispiele für gute Bezeichner erhöhen die Korrekturqualität leicht, sodass die Bewertungen teils von 3{,}75 auf 4{,}00 steigen. Die Modelle verwenden die Anti-Muster-Begriffe jedoch weiterhin selten und benennen Probleme ohne klare Zuordnung zu Kategorien wie~A oder~C.%

\paragraph{Version 3 (kontextreich).}

Der Kontext zu Java-Konventionen und Konsistenz führt zu strukturierteren Analysen mit hohen Werten bei Klarheit und Konsistenz (oft 5 Punkte). Die Anti-Muster-Kategorien werden jedoch nicht systematisch verwendet, sodass Fälle meist nur implizit beschrieben werden.%

\paragraph{Version 4 (mit Anti-Muster-Definitionen).}

Version~V4 mit expliziter Anti-Muster-Definition verbessert die Leistung aller Modelle deutlich: GPT-4o und Qwen3-Coder erreichen bei allen 13 fehlerhaften Beispielen 5{,}00 Punkte mit korrekter Kategorienzuordnung; LLaMA~3.1 erzielt ebenfalls 5{,}00 bei fehlerhaften Fällen, zeigt aber weiterhin Fehlalarme bei korrektem Code.

Die Hinweis-Gestaltung beeinflusst die Modelle stark - ohne explizite Definition erkennen sie Probleme inhaltlich, nutzen aber nicht die Anti-Muster-Begriffe; Version~V4 schließt diese Lücke weitgehend.

\subsection{Analyse der Fehlalarme (False Positives)}

Die Untersuchung analysierte Fehlalarme bei korrektem Code. GPT-4o und Qwen3-Coder erzeugen keine Fehlalarme und bestätigen konsequent die Qualität der Bezeichner (Bewertung 5{,}00).

LLaMA~3.1~70B meldet hingegen systematisch Probleme, etwa bei D1 in allen Versionen: V1--V3 kritisieren ungerechtfertigt, V4 ordnet fälschlich Anti-Muster~B/D zu (Bewertung 4{,}25--4{,}50). V4 verstärkt bei LLaMA die Überinterpretation, verbessert aber bei GPT-4o und Qwen3-Coder die Erkennung ohne Spezifitätsverlust.

\subsection{Zusammenfassung der Evaluationsergebnisse}

Die Evaluation führt zu fünf zentralen Erkenntnissen:%
\begin{itemize}
    \item \textbf{Version~V4 ist entscheidend}. Erst die explizite Definition der Anti-Muster führt dazu, dass alle Modelle die Kategorien~A--F systematisch nutzen; die Bewertungen steigen von durchschnittlich 3{,}75--4{,}75 (V1--V3) auf 5{,}00 (V4) bei fehlerhaften Beispielen.%
    \item \textbf{GPT-4o und Qwen3-Coder zeigen vergleichbare Leistung}. Beide erreichen mit V4 eine Erkennungsrate von 100\,\% bei fehlerhaften Beispielen ohne Fehlalarme bei korrekten Fällen, und die Vorschläge sind in allen Kriterien hervorragend.%
    \item \textbf{LLaMA neigt zu Fehlalarmen}. Trotz guter Ergebnisse bei fehlerhaften Beispielen meldet LLaMA systematisch Probleme bei korrektem Code, und dieses Verhalten bleibt in allen Versionen bestehen.%
    \item \textbf{Inhaltsanalyse ohne Anti-Muster-Begriffe}. Bereits V1--V3 erkennen alle Modelle inhaltliche Probleme wie Nebenwirkungen oder Widersprüche, auch ohne Anti-Muster-Begriffe.%
    \item \textbf{Hohe Konventionskonformität}. Über alle Modelle und Versionen liegen die Werte für Konventionskonformität und Klarheit bei 4--5 Punkten; die Vorschläge folgen durchgängig Java-Standards.%
\end{itemize}

Sprachmodelle erkennen Anti-Muster gut, brauchen aber klare und gute Anweisungen. Die Fehlalarme bei LLaMA machen klar: gute Auffindung bedeutet nicht immer genaue Ergebnisse.%


\newpage
\section*{Kapitel 5}
\section{Diskussion und Schluss}

Diese Arbeit untersucht die Zuverlässigkeit von Sprachmodellen bei der Bewertung von Java-Bezeichnern. Vier Hinweisversionen (V1--V4) wurden an 18 Beispielen mit drei Modellen (GPT-4o, LLaMA~3.1~70B, Qwen3-Coder) getestet.%

Zentrale Ergebnisse:%
\begin{itemize}
    \item Explizite Anti-Muster-Definition in V4 verbessert die Erkennungsrate dramatisch.%
    \item GPT-4o und Qwen3-Coder erreichen 100\,\% Erkennung ohne Fehlalarme.%
    \item LLaMA erzeugt systematisch Fehlalarme bei korrektem Code.%
    \item Vorschläge sind konventionskonform und direkt einsetzbar.%
\end{itemize}

\subsection{Kritische Reflexion}

Die Untersuchung ist begrenzt:%
\begin{itemize}
    \item Nur 18 Beispiele ohne komplexe Projektkontexte.%
    \item Manuelle Bewertung statt automatischer Pipeline.%
    \item Nur drei Modelle, keine Langzeit-Konsistenz geprüft.%
\end{itemize}

Trotzdem zeigen GPT-4o und Qwen3-Coder mit V4 hohe praktische Nutzbarkeit. Die Qualität hängt stark von der Hinweis-Formulierung ab. Sprachmodelle sind wertvolle Assistenten, ersetzen aber keine menschliche Überprüfung.%


% --- Literaturverzeichnis ---
\clearpage
\begin{thebibliography}{99}

    \bibitem{arnaoudova2014}
    Arnaoudova, V.; Di Penta, M.; Antoniol, G. (2014):
    \textit{Linguistic Anti-Patterns: What They Are and How Developers Perceive Them.}
    Empirical Software Engineering.
    Verfügbar unter: \url{https://www.veneraarnaoudova.ca/wp-content/uploads/2014/10/2014-EMSE-Arnaodova-et-al-Perception-LAs.pdf},
    abgerufen am 14.10.2025.

    \bibitem{oracle}
    Oracle Corporation:
    \textit{Naming Conventions.}
    Verfügbar unter: \url{https://www.oracle.com/java/technologies/javase/codeconventions-namingconventions.html},
    abgerufen am 14.10.2025.

    \bibitem{aitomaticprogramming}
    Lyu, M. R.; Rajan, B.; Roychoudhury, A.; Tan, S. H.; Thummalapenta, P.:
    \textit{Automatic Programming: Large Language Models and Beyond.}
    Verfügbar unter: \url{https://dl.acm.org/doi/pdf/10.1145/3708519},
    abgerufen am 15.11.2025.

    \bibitem{identifiernamesinfluencecodequality}
    Butler, S.; Wermelinger, M.; Yu, Y.; Sharp, H. (2010):
    \textit{Exploring the Influence of Identifier Names on Code Quality: An Empirical Study.}
    In: Proceedings of the 14th European Conference on Software Maintenance and Reengineering (CSMR), 15--18 March 2010, Madrid, Spain.
    Verfügbar unter: \url{https://www.researchgate.net/publication/42799923_Exploring_the_Influence_of_Identifier_Names_on_Code_Quality_An_Empirical_Study},
    abgerufen am 26.11.2025.

    \bibitem{llmsmells2025}
    Ghosh Paul, D.; Zhu, H.; Bayley, I. (2025):
    \textit{Investigating the Smells of LLM Generated Code.}
    School of Engineering, Computing and Mathematics, Oxford Brookes University, October 2025.
    Verfügbar unter: \url{https://www.researchgate.net/publication/396223444_Investigating_The_Smells_of_LLM_Generated_Code},
    abgerufen am 26.11.2025.

    \bibitem{llmmaintainablereliable2025}
    Santa Molison, A.; Moraes, M.; Melo, G.; Santos, F.; Assunção, W. K. G. (2025):
    \textit{Is LLM-Generated Code More Maintainable \& Reliable than Human-Written Code?}
    Toronto Metropolitan University; Colorado State University; North Carolina State University, July 2025.
    Verfügbar unter: \url{https://www.researchgate.net/publication/393853113_Is_LLM-Generated_Code_More_Maintainable_Reliable_than_Human-Written_Code},
    abgerufen am 26.11.2025.

    \bibitem{llmmethodnames2025}
    Akram, W.; Jiang, Y.; Zhang, Y.; Khan, H. A.; Liu, H. (2025):
    \textit{LLM-Based Method Name Suggestion with Automatically Generated Context-Rich Prompts.}
    Beijing Institute of Technology; Peking University.
    Verfügbar unter: \url{https://www.researchgate.net/publication/392855381_LLM-Based_Method_Name_Suggestion_with_Automatically_Generated_Context-Rich_Prompts},
    abgerufen am 27.11.2025.

    \bibitem{llmdetection2025}
    Andrade, R.; Torres, J.; Ortiz-Garcés, I. (2025):
    \textit{Enhancing Security in Software Design Patterns and Antipatterns: A Framework for LLM-Based Detection.}
    In: Electronics, 14(3) (2025), Artikel Nr. 586.
    DOI: \url{https://doi.org/10.3390/electronics14030586}.
    Submission received: 16.11.2024; revised: 21.01.2025; accepted: 28.01.2025; published: 01.02.2025.

\end{thebibliography}

\end{document}
